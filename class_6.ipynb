{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced Python Packaging and Deploying Applications\n",
    "\n",
    "## What will we learn in this class?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Packages\n",
    "\n",
    "Packages are a way of structuring Python’s module namespace by using “dotted module names”. For example, the module name A.B designates a submodule named B in a package named A. Just like the use of modules saves the authors of different modules from having to worry about each other’s global variable names, the use of dotted module names saves the authors of multi-module packages like NumPy or Pillow from having to worry about each other’s module names.\n",
    "\n",
    "Packages are a way of structuring Python’s module namespace by using “dotted module names”. For example, the module name A.B designates a submodule named B in a package named A. Just like the use of modules saves the authors of different modules from having to worry about each other’s global variable names, the use of dotted module names saves the authors of multi-module packages like NumPy or Pillow from having to worry about each other’s module names.\n",
    "\n",
    "Suppose you want to design a collection of modules (a “package”) for the uniform handling of sound files and sound data. There are many different sound file formats (usually recognized by their extension, for example: .wav, .aiff, .au), so you may need to create and maintain a growing collection of modules for the conversion between the various file formats. There are also many different operations you might want to perform on sound data (such as mixing, adding echo, applying an equalizer function, creating an artificial stereo effect), so in addition you will be writing a never-ending stream of modules to perform these operations. Here’s a possible structure for your package (expressed in terms of a hierarchical filesystem):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "sound/                          Top-level package\n",
    "      __init__.py               Initialize the sound package\n",
    "      formats/                  Subpackage for file format conversions\n",
    "              __init__.py\n",
    "              wavread.py\n",
    "              wavwrite.py\n",
    "              aiffread.py\n",
    "              aiffwrite.py\n",
    "              auread.py\n",
    "              auwrite.py\n",
    "              ...\n",
    "      effects/                  Subpackage for sound effects\n",
    "              __init__.py\n",
    "              echo.py\n",
    "              surround.py\n",
    "              reverse.py\n",
    "              ...\n",
    "      filters/                  Subpackage for filters\n",
    "              __init__.py\n",
    "              equalizer.py\n",
    "              vocoder.py\n",
    "              karaoke.py\n",
    "              ...\n",
    "```\n",
    "\n",
    "When importing the package, Python searches through the directories on sys.path looking for the package subdirectory.\n",
    "\n",
    "The __init__.py files are required to make Python treat directories containing the file as packages. This prevents directories with a common name, such as string, unintentionally hiding valid modules that occur later on the module search path. In the simplest case, __init__.py can just be an empty file, but it can also execute initialization code for the package or set the __all__ variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Users of the package can import individual modules from the package, for example:\n",
    "```\n",
    "import sound.effects.echo\n",
    "```\n",
    "This loads the submodule sound.effects.echo. It must be referenced with its full name.\n",
    "```\n",
    "sound.effects.echo.echofilter(input, output, delay=0.7, atten=4)\n",
    "```\n",
    "An alternative way of importing the submodule is:\n",
    "\n",
    "```\n",
    "from sound.effects import echo\n",
    "```\n",
    "Note that when using `from package import item`, the item can be either a submodule (or subpackage) of the package, or some other name defined in the package, like a function, class or variable. The import statement first tests whether the item is defined in the package; if not, it assumes it is a module and attempts to load it. If it fails to find it, an ImportError exception is raised.\n",
    "\n",
    "Contrarily, when using syntax like import item.subitem.subsubitem, each item except for the last must be a package; the last item can be a module or a package but can’t be a class or function or variable defined in the previous item.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Importing * From a Package\n",
    "\n",
    "Now what happens when the user writes from `sound.effects import *`? Ideally, one would hope that this somehow goes out to the filesystem, finds which submodules are present in the package, and imports them all. This could take a long time and importing sub-modules might have unwanted side-effects that should only happen when the sub-module is explicitly imported.\n",
    "\n",
    "The only solution is for the package author to provide an explicit index of the package. The import statement uses the following convention: if a package’s `__init__.py` code defines a list named `__all__`, it is taken to be the list of module names that should be imported when `from package import *` is encountered. It is up to the package author to keep this list up-to-date when a new version of the package is released. Package authors may also decide not to support it, if they don’t see a use for importing * from their package. For example, the file `sound/effects/__init__.py` could contain the following code:\n",
    "```\n",
    "__all__ = [\"echo\", \"surround\", \"reverse\"]\n",
    "```\n",
    "\n",
    "This would mean that `from sound.effects import *` would import the three named submodules of the sound package.\n",
    "\n",
    "If `__all__` is not defined, the statement `from sound.effects import *` does not import all submodules from the package sound.effects into the current namespace; it only ensures that the package sound.effects has been imported (possibly running any initialization code in `__init__.py`) and then imports whatever names are defined in the package. This includes any names defined (and submodules explicitly loaded) by `__init__.py`. It also includes any submodules of the package that were explicitly loaded by previous import statements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Packaging Python Projects\n",
    "\n",
    "We will modify a bit the tutorial from Python reference to give more context to what are we doing.  In this tutorial we will build a simple project called class_python_utilities.\n",
    "\n",
    "To create this project locally create the following file structure\n",
    "```\n",
    "class_python_utilities\n",
    "└── class_python_utilities\n",
    "    └── __init__.py\n",
    "```\n",
    "\n",
    "Once you create this structure, you’ll want to run all of the commands in this tutorial within the top-level folder - so be sure to `cd class_python_utilities.`\n",
    "\n",
    "\n",
    "### Creating the packages files\n",
    "You will now create a handful of files to package up this project and prepare it for distribution. Create the new files listed below and place them in the project’s root directory - you will add content to them in the following steps.\n",
    "\n",
    "```\n",
    "class_python_utilities\n",
    "├── LICENSE\n",
    "├── README.md\n",
    "├── class_python_utilities\n",
    "│   └── __init__.py\n",
    "├── setup.py\n",
    "└── tests\n",
    "\n",
    "```\n",
    "`tests/` is a placeholder for unit test files. Leave it empty for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating Setup.py\n",
    "\n",
    "`setup.py` is the build script for setuptools. It tells setuptools about your package (such as the name and version) as well as which code files to include.\n",
    "\n",
    "Open setup.py and enter the following content. Update the package name , this ensures that you have a unique package name and that your package doesn’t conflict with packages uploaded by other people following this tutorial.\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "import setuptools\n",
    "\n",
    "with open(\"README.md\", \"r\") as fh:\n",
    "    long_description = fh.read()\n",
    "    \n",
    "REQUIRED_PACKAGES=[pandas]\n",
    "\n",
    "setuptools.setup(\n",
    "    name=\"class_python_utilities-[YOUR_ID]\", # Replace with your own desired name\n",
    "    version=\"0.0.1\",\n",
    "    author=\"Example Author\",\n",
    "    author_email=\"author@example.com\",\n",
    "    description=\"A small example package\",\n",
    "    long_description=long_description,\n",
    "    long_description_content_type=\"text/markdown\",\n",
    "    url=\"https://github.com/pypa/sampleproject\",\n",
    "    #packages=setuptools.find_packages(),\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    classifiers=[\n",
    "        \"Programming Language :: Python :: 3\",\n",
    "        \"License :: OSI Approved :: MIT License\",\n",
    "        \"Operating System :: OS Independent\",\n",
    "    ],\n",
    "    python_requires='>=3.6',\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "setup() takes several arguments. This example package uses a relatively minimal set:\n",
    "\n",
    " * name is the distribution name of your package. This can be any name as long as only contains letters, numbers, _ , and -. It also must not already be taken on pypi.org. Be sure to update this with your username, as this ensures you won’t try to upload a package with the same name as one which already exists when you upload the package.\n",
    "\n",
    "* version is the package version see PEP 440 for more details on versions.\n",
    "\n",
    "* author and author_email are used to identify the author of the package.\n",
    "\n",
    "* description is a short, one-sentence summary of the package.\n",
    "\n",
    "* long_description is a detailed description of the package. This is shown on the package detail package on the Python Package Index. In this case, the long description is loaded from README.md which is a common pattern.\n",
    "\n",
    "   \n",
    "* long_description_content_type tells the index what type of markup is used for the long description. In this case, it’s Markdown.\n",
    "\n",
    "* url is the URL for the homepage of the project. For many projects, this will just be a link to GitHub, GitLab, Bitbucket, or similar code hosting service.\n",
    "\n",
    "* packages is a list of all Python import packages that should be included in the distribution package. Instead of listing each package manually, we can use find_packages() to automatically discover all packages and subpackages. In this case, the list of packages will be example_pkg as that’s the only package present.\n",
    "* **intall_requires**\n",
    "\n",
    "* classifiers gives the index and pip some additional metadata about your package. In this case, the package is only compatible with Python 3, is licensed under the MIT license, and is OS-independent. You should always include at least which version(s) of Python your package works on, which license your package is available under, and which operating systems your package will work on. For a complete list of classifiers, see https://pypi.org/classifiers/.\n",
    "\n",
    "There are many more than the ones mentioned here. See Packaging and distributing projects for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create README.md\n",
    "\n",
    "Open README.md and enter the following content\n",
    "\n",
    "```\n",
    "#Class Utilities\n",
    "Utilities module for class\n",
    "```\n",
    "\n",
    "### Creating a LICENSE\n",
    "\n",
    "It’s important for every package uploaded to the Python Package Index to include a license. This tells users who install your package the terms under which they can use your package. For help picking a license, see https://choosealicense.com/. Once you have chosen a license, open LICENSE and enter the license text. For example, if you had chosen the MIT license:\n",
    "\n",
    "```\n",
    "Copyright (c) 2018 The Python Packaging Authority\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "```\n",
    "\n",
    "### Generating distribution archives\n",
    "\n",
    "... Lets stop a bit here in the tutorial. If you want to create a package that is distributed in pip. please continue with the tutorial here: https://packaging.python.org/tutorials/packaging-projects/\n",
    "\n",
    "In our case, when most of the time we work in a private setup we will follow another route. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versionising\n",
    "\n",
    "This is a toy example but version number sare meaningul . Given a version number {major}.{minor}.{pathc}, increment\n",
    "\n",
    "major: when you make backward-incompatibale changes\n",
    "minro : when you make backward-compatible features\n",
    "patch: when you fix bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Getting your package into github.\n",
    "\n",
    "before continuing we need to add something to our package. During the course you have been building a few classes and functions. Collect all those functions and add them to `utils.py`\n",
    "\n",
    "```\n",
    "class_python_utilities\n",
    "├── LICENSE\n",
    "├── README.md\n",
    "├── class_python_utilities\n",
    "│   └── __init__.py\n",
    "    └── utils.py\n",
    "├── setup.py\n",
    "└── tests\n",
    "\n",
    "```\n",
    "\n",
    "You shoul have at least \n",
    "```\n",
    "class PortfolioModels\n",
    "def Perceptron(train_data, test_data)\n",
    "def Perceptron(train_data, test_data):\n",
    "class NonLinearRegression:\n",
    "\n",
    "```\n",
    "\n",
    "Add these functions to utils, with their respective required libraries. also update setup.py to reflect this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "* Create a new empty repository in github called `class_python_utilities`\n",
    "* Follow the instructions and initialize a repository in the root  directoy of `class_python_utilities`\n",
    "```\n",
    "git init\n",
    "git add - A\n",
    "git commit -m \"first commit\"\n",
    "git remote add origin https://github.com/[GIT_USER]/class_python_utilities.git\n",
    "git push -u origin master\n",
    "                \n",
    "```\n",
    "\n",
    "\n",
    "Now you can install your package in your environment as\n",
    "\n",
    "```\n",
    "pip insttall git+https://github.com/JalatorrS1/class_python_utilities.git\n",
    "\n",
    "```\n",
    "\n",
    "After this lets import the package utils functions and  test our code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "importing data: 100%|██████████| 12/12 [00:12<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "from class_python_utils.utils import *\n",
    "pm=PortfolioModels(data_repo=\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an executable package\n",
    "\n",
    "Lets add another file to our project\n",
    "```\n",
    "class_python_utilities\n",
    "├── LICENSE\n",
    "├── README.md\n",
    "├── class_python_utilities\n",
    "│   └── __init__.py\n",
    "    └── utils.py\n",
    "    └── __main__.py\n",
    "├── setup.py\n",
    "└── tests\n",
    "```\n",
    "\n",
    "and add the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from .utils import *\n",
    "\n",
    "\n",
    "def get_parser():\n",
    "    \"\"\"Get parser object for script xy.py.\"\"\"\n",
    "    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "\n",
    "    parser = ArgumentParser(\n",
    "        description=\"Financial Data Harvest Luigi Tasks\", formatter_class=ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--portfolio_path\",\n",
    "         help=\"Read portfolio data\",\n",
    "        required=False\n",
    "    )\n",
    "\n",
    "    return parser\n",
    "\n",
    "def main(args):\n",
    "\n",
    "\n",
    "   pm = PortfolioModels(data_repo= args.portfolio_path)\n",
    "   print(pm.all_closes.head())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "   parser=get_parser()\n",
    "   args = parser.parse_args()\n",
    "   main(args)\n",
    "```\n",
    "\n",
    "what and why are we doing this?\n",
    "\n",
    "\n",
    "Test your module in your enviroment running\n",
    "\n",
    "```\n",
    "python -m class_python_utils --portfolio_path /home/jose/code/intro_python_finance/data/\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containers (Docker)\n",
    "\n",
    "<img src=\"static/img/docker.png\">\n",
    "\n",
    "### What is Docker\n",
    "\n",
    " Docker is a tool that allows developers, sys-admins etc. to easily deploy their applications in a sandbox (called containers) to run on the host operating system i.e. Linux. The key benefit of Docker is that it allows users to package an application with all of its dependencies into a standardized unit for software development. Unlike virtual machines, containers do not have high overhead and hence enable more efficient usage of the underlying system and resources.\n",
    " \n",
    " ### What are containers?\n",
    "\n",
    "The industry standard today is to use Virtual Machines (VMs) to run software applications. VMs run applications inside a guest Operating System, which runs on virtual hardware powered by the server’s host OS.\n",
    "\n",
    "VMs are great at providing full process isolation for applications: there are very few ways a problem in the host operating system can affect the software running in the guest operating system, and vice-versa. But this isolation comes at great cost — the computational overhead spent virtualizing hardware for a guest OS to use is substantial.\n",
    "\n",
    "Containers take a different approach: by leveraging the low-level mechanics of the host operating system, containers provide most of the isolation of virtual machines at a fraction of the computing power.\n",
    "\n",
    "### Why use containers?\n",
    "\n",
    "Containers offer a logical packaging mechanism in which applications can be abstracted from the environment in which they actually run. This decoupling allows container-based applications to be deployed easily and consistently, regardless of whether the target environment is a private data center, the public cloud, or even a developer’s personal laptop. This gives developers the ability to create predictable environments that are isolated from the rest of the applications and can be run anywhere.\n",
    "\n",
    "From an operations standpoint, apart from portability containers also give more granular control over resources giving your infrastructure improved efficiency which can result in better utilization of your compute resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to build a fully reproducible  verison of our package\n",
    "\n",
    "### building the Data Science Container\n",
    "#### The Base Alpine Linux Image\n",
    "Alpine Linux is a tiny Linux distribution designed for power users who appreciate security, simplicity and resource efficiency.\n",
    "As claimed by Alpine:\n",
    "Small. Simple. Secure. Alpine Linux is a security-oriented, lightweight Linux distribution based on musl libc and busybox.\n",
    "The Alpine image is surprisingly tiny with a size of no more than 8MB for containers. With minimal packages installed to reduce the attack surface on the underlying container. This makes Alpine an image of choice for our data science container.\n",
    "Downloading and Running an Alpine Linux container is as simple as:\n",
    "\n",
    "```\n",
    "docker container run --rm alpine:latest cat /etc/os-release\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### The DockerFile\n",
    "Docker can build images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession.\n",
    "\n",
    "#### Usage\n",
    "The docker build command builds an image from a Dockerfile and a context. The build’s context is the set of files at a specified location PATH or URL. The PATH is a directory on your local filesystem. The URL is a Git repository location.\n",
    "A context is processed recursively. So, a PATH includes any subdirectories and the URL includes the repository and its submodules. This example shows a build command that uses the current directory as context:\n",
    "\n",
    "\n",
    "The build is run by the Docker daemon, not by the CLI. The first thing a build process does is send the entire context (recursively) to the daemon. In most cases, it’s best to start with an empty directory as context and keep your Dockerfile in that directory. Add only the files needed for building the Dockerfile.\n",
    "Warning\n",
    "Do not use your root directory, /, as the PATH as it causes the build to transfer the entire contents of your hard drive to the Docker daemon.\n",
    "...\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "The Docker daemon runs the instructions in the Dockerfile one-by-one, committing the result of each instruction to a new image if necessary, before finally outputting the ID of your new image. The Docker daemon will automatically clean up the context you sent.\n",
    "Note that each instruction is run independently, and causes a new image to be created - so RUN cd /tmp will not have any effect on the next instructions.\n",
    "Whenever possible, Docker will re-use the intermediate images (cache), to accelerate the docker build process significantly. This is indicated by the Using cache message in the console output. (For more information, see the Dockerfile best practices guide:\n",
    "\n",
    "source\n",
    "https://docs.docker.com/engine/reference/builder/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "FROM alpine:latest\n",
    "\n",
    "\n",
    "WORKDIR /var/www/\n",
    "\n",
    "\n",
    "\n",
    "# SOFTWARE PACKAGES\n",
    "\n",
    "#   * musl: standard C library\n",
    "\n",
    "#   * lib6-compat: compatibility libraries for glibc\n",
    "\n",
    "#   * linux-headers: commonly needed, and an unusual package name from Alpine.\n",
    "\n",
    "#   * build-base: used so we include the basic development packages (gcc)\n",
    "\n",
    "#   * bash: so we can access /bin/bash\n",
    "\n",
    "#   * git: to ease up clones of repos\n",
    "\n",
    "#   * ca-certificates: for SSL verification during Pip and easy_install\n",
    "\n",
    "#   * freetype: library used to render text onto bitmaps, and provides support font-related operations\n",
    "\n",
    "#   * libgfortran: contains a Fortran shared library, needed to run Fortran\n",
    "\n",
    "#   * libgcc: contains shared code that would be inefficient to duplicate every time as well as auxiliary helper routines and runtime support\n",
    "\n",
    "#   * libstdc++: The GNU Standard C++ Library. This package contains an additional runtime library for C++ programs built with the GNU compiler\n",
    "\n",
    "#   * openblas: open source implementation of the BLAS(Basic Linear Algebra Subprograms) API with many hand-crafted optimizations for specific processor types\n",
    "\n",
    "#   * tcl: scripting language\n",
    "\n",
    "#   * tk: GUI toolkit for the Tcl scripting language\n",
    "\n",
    "#   * libssl1.0: SSL shared libraries\n",
    "\n",
    "ENV PACKAGES=\"\\\n",
    "\n",
    "    dumb-init \\\n",
    "\n",
    "    musl \\\n",
    "\n",
    "    libc6-compat \\\n",
    "\n",
    "    linux-headers \\\n",
    "\n",
    "    build-base \\\n",
    "\n",
    "    bash \\\n",
    "\n",
    "    git \\\n",
    "\n",
    "    ca-certificates \\\n",
    "\n",
    "    freetype \\\n",
    "\n",
    "    libgfortran \\\n",
    "\n",
    "    libgcc \\\n",
    "\n",
    "    libstdc++ \\\n",
    "\n",
    "    openblas \\\n",
    "\n",
    "    tcl \\\n",
    "\n",
    "    tk \\\n",
    "\n",
    "    libssl1.0 \\\n",
    "\n",
    "    \"\n",
    "\n",
    "\n",
    "\n",
    "# PYTHON DATA SCIENCE PACKAGES\n",
    "\n",
    "#   * numpy: support for large, multi-dimensional arrays and matrices\n",
    "\n",
    "#   * matplotlib: plotting library for Python and its numerical mathematics extension NumPy.\n",
    "\n",
    "#   * scipy: library used for scientific computing and technical computing\n",
    "\n",
    "#   * scikit-learn: machine learning library integrates with NumPy and SciPy\n",
    "\n",
    "#   * pandas: library providing high-performance, easy-to-use data structures and data analysis tools\n",
    "\n",
    "#   * class_utils: Our great package\n",
    "\n",
    "ENV PYTHON_PACKAGES=\"\\\n",
    "\n",
    "    numpy \\\n",
    "\n",
    "    matplotlib \\\n",
    "\n",
    "    scipy \\\n",
    "\n",
    "    scikit-learn \\\n",
    "\n",
    "    pandas \\\n",
    "\n",
    "    git+https://github.com/JalatorrS1/class_python_utilities.git \\\n",
    "\n",
    "    \" \n",
    "\n",
    "\n",
    "\n",
    "RUN apk add --no-cache --virtual build-dependencies python3 \\\n",
    "\n",
    "    && apk add --virtual build-runtime \\\n",
    "\n",
    "    build-base python3-dev openblas-dev freetype-dev pkgconfig gfortran \\\n",
    "\n",
    "    && ln -s /usr/include/locale.h /usr/include/xlocale.h \\\n",
    "\n",
    "    && python3 -m ensurepip \\\n",
    "\n",
    "    && rm -r /usr/lib/python*/ensurepip \\\n",
    "\n",
    "    && pip3 install --upgrade pip setuptools \\\n",
    "\n",
    "    && ln -sf /usr/bin/python3 /usr/bin/python \\\n",
    "\n",
    "    && ln -sf pip3 /usr/bin/pip \\\n",
    "\n",
    "    && rm -r /root/.cache \\\n",
    "\n",
    "    && pip install --no-cache-dir $PYTHON_PACKAGES \\\n",
    "\n",
    "    && apk del build-runtime \\\n",
    "\n",
    "    && apk add --no-cache --virtual build-dependencies $PACKAGES \\\n",
    "\n",
    "    && rm -rf /var/cache/apk/*\n",
    "\n",
    "\n",
    "\n",
    "CMD [\"python3\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FROM directive is used to set alpine:latest as the base image. Using the WORKDIR directive we set the /var/www as the working directory for our container. The ENV PACKAGES lists the software packages required for our container like git, blas and libgfortran. The python packages for our data science container are defined in the ENV PACKAGES.\n",
    "We have combined all the commands under a single Dockerfile RUN directive to reduce the number of layers which in turn helps in reducing the resultant image size.\n",
    "\n",
    "We have combined all the commands under a single Dockerfile RUN directive to reduce the number of layers which in turn helps in reducing the resultant image size\n",
    "\n",
    "\n",
    "Now run \n",
    "\n",
    "```\n",
    "docker build -t class-image .\n",
    "```\n",
    "\n",
    "What happend? And how can you fix this error?\n",
    "\n",
    "this happend becase we did not had git installed. remember that each image is a fresh recreation of what the dockerfile is commanding. in this case we need to add\n",
    "\n",
    "```\n",
    "   && apk add git \\\n",
    "```\n",
    "\n",
    "A cool features of docker is the avility to tag image. For example instead fo waiting hours everytime that scikitlearn is building we can  create that image. tag it. upload it to dockerhub and then someone can just pull it without the need to rebuild that stage. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another error, Well it turns out that installing scikit-learn in alpine is not an easy task. Can be done but takes time. to avoid wasting time lets use a prebuild image from docker-hub. build with anaconda pre-installed\n",
    "\n",
    "\n",
    "\n",
    "you can check the images built in your system with the command `docker images`\n",
    "\n",
    "now lets bash inside of the image\n",
    "```\n",
    "docker run -i -t class-image /bin/bash\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "Create an account in docker hub , tag and upload your image. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "p38_pipenv_class",
   "language": "python",
   "name": "p38_pipenv_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
